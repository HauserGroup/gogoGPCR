{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a57b509",
   "metadata": {},
   "source": [
    "# Create a MatrixTable and QC the hell out of it\n",
    "## Import stuff and set your parameters\n",
    "First, we import necessary libraries and configurations from config.toml. Then we initialise Spark and Hail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5661cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from distutils.version import LooseVersion\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import dxdata\n",
    "import dxpy\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import toml\n",
    "from src.matrixtables import *\n",
    "from src.utils import show_stats\n",
    "\n",
    "module_path = Path(\"..\").resolve().__str__()\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    Path(\"../tmp\").resolve().mkdir(parents=True, exists_ok=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "hl.plot.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b485eb2",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "with open(\"../config.toml\") as f:\n",
    "    conf = toml.load(f)\n",
    "\n",
    "IMPORT = conf[\"IMPORT\"]\n",
    "NAME = conf[\"NAME\"]\n",
    "VCF_VERSION = IMPORT[\"VCF_VERSION\"]\n",
    "REFERENCE_GENOME = conf[\"REFERENCE_GENOME\"]\n",
    "DATABASE = IMPORT[\"DATABASE\"]\n",
    "\n",
    "LOG_FILE = (\n",
    "    Path(IMPORT[\"LOG_DIR\"], f\"{NAME}_{datetime.now().strftime('%H%M')}.log\")\n",
    "    .resolve()\n",
    "    .__str__()\n",
    ")\n",
    "MAP_FILE = Path(IMPORT[\"MAPPING_FILE\"]).resolve().__str__()\n",
    "INT_FILE = Path(IMPORT[\"INTERVAL_FILE\"]).resolve().__str__()\n",
    "GENE_FILE = Path(IMPORT[\"GENE_FILE\"]).resolve().__str__()\n",
    "FILTER_FILE = (\n",
    "    Path(conf[\"SAMPLE_QC\"][\"DATA_DIR\"], conf[\"SAMPLE_QC\"][\"SAMPLE_FILTER_FILE\"])\n",
    "    .resolve()\n",
    "    .__str__()\n",
    ")\n",
    "\n",
    "VCF_DIR = Path(IMPORT[\"VCF_DIR\"]).resolve().__str__()\n",
    "\n",
    "DOWNSAMPLE_P = IMPORT.get(\"DOWNSAMPLE_P\", None)\n",
    "\n",
    "SNV_ONLY = conf[\"ANNOTATE\"][\"SNV_ONLY\"]\n",
    "USE_VEP = conf[\"ANNOTATE\"][\"USE_VEP\"]\n",
    "MISSENSE_ONLY = conf[\"ANNOTATE\"][\"MISSENSE_ONLY\"]\n",
    "\n",
    "VEP_JSON = Path(conf[\"ANNOTATE\"][\"VEP_JSON\"]).resolve().__str__()\n",
    "\n",
    "ANNOTATION_DIR = conf[\"ANNOTATE\"][\"ANNOTATION_DIR\"]\n",
    "\n",
    "MIN_DP = conf[\"ENTRY_QC\"][\"MIN_DP\"]\n",
    "MIN_GQ = conf[\"ENTRY_QC\"][\"MIN_GQ\"]\n",
    "MIN_PL = conf[\"ENTRY_QC\"][\"MIN_PL\"]\n",
    "\n",
    "MIN_P_HWE = conf[\"VARIANT_QC\"][\"MIN_P_HWE\"]\n",
    "MIN_VAR_GQ = conf[\"VARIANT_QC\"][\"MIN_VAR_GQ\"]\n",
    "\n",
    "MIN_CALL_RATE = conf[\"SAMPLE_QC\"][\"MIN_CALL_RATE\"]\n",
    "MIN_MEAN_DP = conf[\"SAMPLE_QC\"][\"MIN_MEAN_DP\"]\n",
    "MIN_MEAN_GQ = conf[\"SAMPLE_QC\"][\"MIN_MEAN_GQ\"]\n",
    "\n",
    "TMP_DIR = conf[\"EXPORT\"][\"TMP_DIR\"]\n",
    "\n",
    "BGEN_FILE = Path(TMP_DIR, f\"{NAME}\").resolve().__str__()\n",
    "ANNOTATIONS_FILE = Path(TMP_DIR, f\"{NAME}.annotations\").resolve().__str__()\n",
    "SETLIST_FILE = Path(TMP_DIR, f\"{NAME}.setlist\").resolve().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d720a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark and Hail\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "try:\n",
    "    mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]\n",
    "except Exception as e:\n",
    "    print(e.message)\n",
    "    spark.sql(f\"CREATE DATABASE {DATABASE} LOCATION  'dnax://'\")\n",
    "    mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]\n",
    "\n",
    "# this breaks export_bgen for now\n",
    "# hl.init(sc=sc, default_reference=REFERENCE_GENOME, log=LOG_FILE, tmp_dir=f'dnax://{mt_database}/tmp/')\n",
    "\n",
    "hl.init(sc=sc, default_reference=REFERENCE_GENOME, log=LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GENE_FILE, \"r\") as file:\n",
    "    genes = file.read().splitlines()\n",
    "\n",
    "mapping = pd.read_csv(MAP_FILE, sep=\"\\t\").set_index(\"HGNC\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "mt = import_mt(genes, mapping, vcf_dir=VCF_DIR, vcf_version=VCF_VERSION).key_rows_by(\n",
    "    \"locus\", \"alleles\"\n",
    ")  # .checkpoint(checkpoint_file)\n",
    "\n",
    "v, s = mt.count()\n",
    "pprint(f\"{v} variants and {s} samples after import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "stage = \"raw\"\n",
    "checkpoint_file = f\"/tmp/{NAME}.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc57748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample\n",
    "if DOWNSAMPLE_P is not None:\n",
    "    mt = downsample_mt(mt, DOWNSAMPLE_P)\n",
    "\n",
    "    pprint(f\"{mt.count_cols()} samples after downsampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_qc_mt(\n",
    "    mt: hl.matrixtable.MatrixTable,\n",
    "    bed_file: Union[str, Path],\n",
    ") -> hl.matrixtable.MatrixTable:\n",
    "    \"\"\"Filter to only Target region used by the WES capture experiment\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mt : hl.matrixtable.MatrixTable\n",
    "        MatrixTable\n",
    "    intervals : str\n",
    "        .BED file of targeted capture regions which meet quality standards\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hl.matrixtable.MatrixTable\n",
    "        MatrixTable filtered to only target regions\n",
    "    \"\"\"\n",
    "\n",
    "    interval_table = hl.import_bed(\n",
    "        bed_file,\n",
    "        reference_genome=\"GRCh38\",\n",
    "        # filter=f\"^(?!(chr{mapping['GRCh38_region']}))\",\n",
    "    )\n",
    "\n",
    "    mt = mt.filter_rows(hl.is_defined(interval_table[mt.locus]))\n",
    "\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c45680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval QC\n",
    "mt = interval_qc_mt(mt, \"file:\" + INT_FILE)\n",
    "\n",
    "pprint(f\"{mt.count_rows()} variants after interval filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb447c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split multi\n",
    "mt = mt.filter_rows(mt.alleles.length() <= 6)\n",
    "mt = smart_split_multi_mt(mt)\n",
    "\n",
    "pprint(f\"{mt.count_rows()} variants with not more than 6 alleles after splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100111fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if USE_VEP:\n",
    "    mt = hl.vep(mt, \"file:\" + VEP_JSON)\n",
    "\n",
    "    is_MANE = mt.aggregate_rows(\n",
    "        hl.agg.all(hl.is_defined(mt.vep.transcript_consequences.mane_select))\n",
    "    )\n",
    "    assert is_MANE, \"Selected transcript may not be MANE Select. Check manually.\"\n",
    "\n",
    "    mt = mt.annotate_rows(\n",
    "        protCons=mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[0]\n",
    "        + hl.str(mt.vep.transcript_consequences.protein_end[0])\n",
    "        + mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[-1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_FILE = Path(ANNOTATION_DIR, f\"{NAME}.tsv\").resolve().__str__()\n",
    "mt = annotate_mt(mt=mt, gene=NAME, annotations=ANNOTATION_FILE)\n",
    "\n",
    "interesting = mt.filter_rows(\n",
    "    (hl.is_defined(mt.annotations)) & (hl.agg.any(mt.GT.is_non_ref()))\n",
    ").count_rows()\n",
    "pprint(f\"{interesting} annotated variants found before QC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c37c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "stage = \"QC1\"\n",
    "checkpoint_file = f\"/tmp/{NAME}.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "# show_stats(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Withdrawn\n",
    "mt = mt.filter_cols(~mt.s.startswith(\"W\"))\n",
    "\n",
    "print(f\"Samples remaining after removing withdrawn participants: {mt.count_cols()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fca2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter samples\n",
    "samples_to_remove = hl.import_table(\"file:\" + FILTER_FILE, key=\"eid\")\n",
    "mt = mt.anti_join_cols(samples_to_remove)\n",
    "print(f\"Samples remaining after removing related samples: {mt.count_cols()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d793a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample QC\n",
    "mt = sample_QC_mt(mt, MIN_CALL_RATE, MIN_MEAN_DP, MIN_MEAN_GQ)\n",
    "\n",
    "print(f\"Samples remaining after QC: {mt.count_cols()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant QC\n",
    "mt = variant_QC_mt(mt, MIN_P_HWE, MIN_VAR_GQ)\n",
    "\n",
    "interesting = mt.filter_rows(\n",
    "    (hl.is_defined(mt.annotations)) & (hl.agg.any(mt.GT.is_non_ref()))\n",
    ").count_rows()\n",
    "print(\n",
    "    f\"{mt.count_rows()} variants remaining after QC of which {interesting} are annotated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bca1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genotype GQ\n",
    "mt = genotype_filter_mt(mt, MIN_DP, MIN_GQ, True)\n",
    "\n",
    "missing = mt.aggregate_entries(hl.agg.sum(~hl.is_defined(mt.GT)))\n",
    "pprint(f\"{missing} missing or filtered entries after Call QC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "stage = \"QC2\"\n",
    "checkpoint_file = f\"/tmp/{GENE}.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "show_stats(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGEN\n",
    "write_bgen(mt, \"file:\" + BGEN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANNOTATIONS\n",
    "\n",
    "mt = add_varid(mt)\n",
    "\n",
    "annotations = (\n",
    "    mt.select_rows(\n",
    "        varid=mt.varid,\n",
    "        gene=mt.vep.transcript_consequences.gene_symbol[0],\n",
    "        annotation=mt.annotation,\n",
    "    )\n",
    "    .rows()\n",
    "    .key_by(\"varid\")\n",
    "    .drop(\"locus\")\n",
    "    .drop(\"alleles\")\n",
    ")\n",
    "annotations.export(\"file:\" + ANNOTATIONS_FILE, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETLIST\n",
    "position = mt.aggregate_rows(hl.agg.min(mt.locus.position))\n",
    "names = mt.varid.collect()\n",
    "names_str = \",\".join(names)\n",
    "\n",
    "line = f\"{mt.vep.transcript_consequences.gene_symbol[0].collect()[0]}\\t{mt.locus.contig.collect()[0]}\\t{position}\\t{names_str}\"\n",
    "\n",
    "with open(SETLIST_FILE, \"w\") as f:\n",
    "    f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgen_file = BGEN_FILE + \".bgen\"\n",
    "sample_file = BGEN_FILE + \".sample\"\n",
    "\n",
    "# subprocess.run([\"dx\", \"upload\", bgen_file, sample_file, ANNOTATIONS_FILE, SETLIST_FILE, \"--path\", \"/data/burden/\"], check = True, shell = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ffe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mt.select_cols(ID_1=mt.s, ID_2=mt.s, missing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.cols().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE = \"final\"\n",
    "# WRITE_PATH = \"dnax://\" + mt_database + f\"/{GENE}.{STAGE}.mt\"\n",
    "\n",
    "# mt.write(WRITE_PATH, overwrite = True)\n",
    "show_stats(mt)\n",
    "\n",
    "# STAGE = \"final\"\n",
    "# WRITE_PATH = \"dnax://\" + mt_database + f\"/{GENE}.{STAGE}.mt\"\n",
    "\n",
    "# mt = hl.read_matrix_table(WRITE_PATH)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
