{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97911237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "import toml\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "from subprocess import run\n",
    "from pathlib import Path\n",
    "\n",
    "import hail as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debcd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fffe4ef9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"../config.toml\") as f:\n",
    "    conf = toml.load(f)\n",
    "\n",
    "RAW_REL_FILE = conf[\"SAMPLE_QC\"][\"UKB_REL_DAT_FILE\"]\n",
    "REL_FILE = conf[\"SAMPLE_QC\"][\"REL_FILE\"]\n",
    "SAMP_FILE = conf[\"SAMPLE_QC\"][\"SAMP_FILE\"]\n",
    "\n",
    "MAX_KINSHIP = conf[\"SAMPLE_QC\"][\"MAX_KINSHIP\"]\n",
    "\n",
    "LOG_FILE = Path(conf[\"IMPORT\"][\"LOG_DIR\"], f\"sample_filters.log\").resolve().__str__()\n",
    "TMP_DIR = Path(conf[\"EXPORT\"][\"TMP_DIR\"])\n",
    "DATA_DIR = conf[\"SAMPLE_QC\"][\"DATA_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdea5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\n",
      "SparkUI available at http://ip-10-60-170-42.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.61-3c86d3ba497a\n",
      "LOGGING: writing to /opt/notebooks/gogoGPCR/hail_logs/sample_filters.log\n"
     ]
    }
   ],
   "source": [
    "hl.init(sc=sc, default_reference='GRCh38', log=LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36852c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41eeb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89d85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1043f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_for_id(field_id):\n",
    "\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    \n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9837c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"22027\", \"22019\", \"22006\", \"22021\"]\n",
    "field_names = [fields_for_id(id) for id in fields] #fields_for_id(\"22027\") + fields_for_id(\"22019\") + fields_for_id(\"22006\") + fields_for_id(\"22021\")\n",
    "field_names = [\"eid\"] + [field.name for fields in field_names for field in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6deaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = participant.retrieve_fields(names=field_names, engine=dxdata.connect(), coding_values=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c49541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------------------+\n",
      "|eid    |p22027|p22019|p22006   |p22021                          |\n",
      "+-------+------+------+---------+--------------------------------+\n",
      "|3888244|null  |null  |Caucasian|No kinship found                |\n",
      "|1795659|null  |null  |Caucasian|No kinship found                |\n",
      "|2084720|null  |null  |Caucasian|At least one relative identified|\n",
      "|3742232|null  |null  |Caucasian|At least one relative identified|\n",
      "|1094442|null  |null  |Caucasian|At least one relative identified|\n",
      "+-------+------+------+---------+--------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4063d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((df.p22006 == \"Caucasian\") &\n",
    "          (df.p22027.isNull()) &\n",
    "          (df.p22019.isNull()) &\n",
    "          (df.p22021 != \"Participant excluded from kinship inference process\") & \n",
    "          (df.p22021 != \"Ten or more third-degree relatives identified\"))\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a84b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMP_PATH = TMP_DIR / SAMP_FILE\n",
    "df = df.select(\"eid\")\n",
    "df.toPandas().to_csv(SAMP_PATH, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436a0ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['dx', 'upload', '/opt/notebooks/gogoGPCR/data/samples_to_keep.tsv', '--path', '/data/processed/'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run([\"dx\", \"upload\", SAMP_PATH, \"--path\", DATA_DIR], check = True, shell = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "794f5d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 08:37:16 Hail: INFO: Reading table to impute column types\n",
      "2021-09-28 08:37:20 Hail: INFO: Finished type imputation\n",
      "  Loading field 'ID1' as type str (user-supplied type)\n",
      "  Loading field 'ID2' as type str (user-supplied type)\n",
      "  Loading field 'HetHet' as type float64 (imputed)\n",
      "  Loading field 'IBS0' as type float64 (imputed)\n",
      "  Loading field 'Kinship' as type float64 (imputed)\n",
      "2021-09-28 08:37:23 Hail: INFO: wrote table with 40241 rows in 1 partition to /tmp/0c7UNWoPsEiWd4rmvYOf9b\n",
      "    Total size: 622.02 KiB\n",
      "    * Rows: 622.01 KiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 40241 rows (622.01 KiB)\n",
      "    * Largest partition:  40241 rows (622.01 KiB)\n",
      "2021-09-28 08:37:25 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34824"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = hl.import_table(\n",
    "        \"file:\" + RAW_REL_FILE,\n",
    "        delimiter=\" \",\n",
    "        impute=True,\n",
    "        types={\"ID1\": \"str\", \"ID2\": \"str\"},\n",
    "    )\n",
    "\n",
    "rel = rel.filter(rel.Kinship > MAX_KINSHIP, keep=True)\n",
    "\n",
    "related_samples_to_remove = hl.maximal_independent_set(\n",
    "    i=rel.ID1,\n",
    "    j=rel.ID2,\n",
    "    keep=False,\n",
    ").rename({\"node\": \"eid\"}).key_by(\"eid\")\n",
    "\n",
    "related_samples_to_remove.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d60e350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 08:43:56 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2021-09-28 08:43:56 Hail: INFO: merging 1 files totalling 272.1K...\n",
      "2021-09-28 08:43:56 Hail: INFO: while writing:\n",
      "    file:/opt/notebooks/gogoGPCR/tmp/samples_to_remove.tsv\n",
      "  merge time: 43.536ms\n"
     ]
    }
   ],
   "source": [
    "REL_PATH = (TMP_DIR / REL_FILE).resolve().__str__()\n",
    "related_samples_to_remove.export(\"file:\" + REL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a0c29a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['dx', 'upload', '/opt/notebooks/gogoGPCR/tmp/samples_to_remove.tsv', '--path', '/data/processed/'], returncode=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run([\"dx\", \"upload\", REL_PATH, \"--path\", DATA_DIR, check = True, shell = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
