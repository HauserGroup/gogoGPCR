{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d209bddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import dxpy\n",
    "import hail as hl\n",
    "from datetime import datetime\n",
    "from matrixtables import import_mt, interval_qc_mt, smart_split_multi_mt\n",
    "from subprocess import run\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "\n",
    "Path(\"/tmp\").resolve().mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc936a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\n",
      "SparkUI available at http://ip-10-60-131-24.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.78-b17627756568\n",
      "LOGGING: writing to /opt/notebooks/gogoGPCR/notebooks/hail_logs/GIPR_1155.log\n"
     ]
    }
   ],
   "source": [
    "# Spark and Hail\n",
    "VCF_DIR = Path(\"/mnt/project/Bulk/Exome sequences/Population level exome OQFE variants, pVCF format - final release/\")\n",
    "DATABASE = \"matrix_tables\"\n",
    "REFERENCE_GENOME = 'GRCh38'\n",
    "\n",
    "LOG_FILE = (\n",
    "    Path(\"../hail_logs\", f\"GIPR_{datetime.now().strftime('%H%M')}.log\")\n",
    "    .resolve()\n",
    "    .__str__()\n",
    ")\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "try:\n",
    "    mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]\n",
    "except Exception as e:\n",
    "    spark.sql(f\"CREATE DATABASE {DATABASE} LOCATION  'dnax://'\")\n",
    "    mt_database = dxpy.find_one_data_object(name=DATABASE)[\"id\"]\n",
    "\n",
    "hl.init(sc=sc, default_reference=REFERENCE_GENOME, log=LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a769ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGNC                                                                     GIPR\n",
       "entry_name                                                         gipr_human\n",
       "name                                                             GIP receptor\n",
       "accession                                                              P48546\n",
       "family                                                        002_001_003_002\n",
       "species                                                          Homo sapiens\n",
       "residue_numbering_scheme                                            GPCRdb(B)\n",
       "sequence                    MTTSPILQLLLRLSLCGLLLQRAETGSKGQTAGELYQRWERYRREC...\n",
       "genes                                                                ['GIPR']\n",
       "ENSG                                                          ENSG00000010310\n",
       "ENST                                                          ENST00000590918\n",
       "type                                                                     GPCR\n",
       "GRCh37_start                                                      4.61715e+07\n",
       "GRCh37_end                                                         4.6187e+07\n",
       "GRCh37_strand                                                               1\n",
       "GRCh38_start                                                         45668221\n",
       "GRCh38_end                                                           45683722\n",
       "GRCh38_strand                                                               1\n",
       "GRCh38_region                                                              19\n",
       "Notes                                                                     NaN\n",
       "VCF_block                                                                  46\n",
       "Name: GIPR, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in metadata and region\n",
    "MAPPING_FILE = Path(\"../../data/misc/mappings_with_blocks.tsv\").resolve()\n",
    "mapping = pd.read_csv(MAPPING_FILE, sep=\"\\t\").set_index(\"HGNC\", drop=False)\n",
    "mapping.loc[\"GIPR\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed30314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VCF as matrix table and filter to only GIPR\n",
    "mt = import_mt([\"GIPR\"], mapping, vcf_dir=VCF_DIR, vcf_version=\"v1\").key_rows_by(\n",
    "    \"locus\", \"alleles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579f1b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:02:04 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:16 Hail: INFO: wrote matrix table with 1214 rows and 469835 columns in 1 partition to /tmp/GIPR.RAW.cp.mt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214 variants and 469835 samples after import\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint because Hail likes checkpointing\n",
    "stage = \"RAW\"\n",
    "checkpoint_file = f\"/tmp/GIPR.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "\n",
    "v, s = mt.count()\n",
    "print(f\"{v} variants and {s} samples after import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a0a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:10:18 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "2023-01-31 11:10:20 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 variants after interval filtering\n"
     ]
    }
   ],
   "source": [
    "# Filter to only WES target regions \n",
    "INTERVAL_FILE=Path(\"../../data/misc/xgen_plus_spikein.b38.bed\").resolve()\n",
    "run([\"hadoop\", \"fs\", \"-put\", str(INTERVAL_FILE), \"/tmp\"])\n",
    "\n",
    "interval_table = hl.import_bed(\n",
    "        f\"/tmp/{INTERVAL_FILE.name}\",\n",
    "        reference_genome=\"GRCh38\",\n",
    "    )\n",
    "\n",
    "mt = mt.filter_rows(hl.is_defined(interval_table[mt.locus]))\n",
    "print(f\"{mt.count_rows()} variants after interval filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4768a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:10:23 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:25 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:27 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555 variants with not more than 6 alleles after splitting\n"
     ]
    }
   ],
   "source": [
    "# Split multi alleles \n",
    "mt = mt.filter_rows(mt.alleles.length() <= 6)\n",
    "mt = smart_split_multi_mt(mt)\n",
    "\n",
    "print(f\"{mt.count_rows()} variants with not more than 6 alleles after splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e550cb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:10:29 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:30 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:31 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-01-31 11:10:32 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:34 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:35 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:36 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-01-31 11:10:37 Hail: INFO: Coerced sorted dataset\n"
     ]
    }
   ],
   "source": [
    "# Annotate with VEP and generate protein consequence\n",
    "VEP_JSON = Path(\"../../data/misc/GRCh38_VEP.json\").resolve()\n",
    "\n",
    "mt = hl.vep(mt, f\"file:{VEP_JSON}\")\n",
    "\n",
    "is_MANE = mt.aggregate_rows(\n",
    "    hl.agg.all(hl.is_defined(mt.vep.transcript_consequences.mane_select))\n",
    ")\n",
    "assert is_MANE, \"Selected transcript may not be MANE Select. Check manually.\"\n",
    "\n",
    "mt = mt.annotate_rows(\n",
    "    protCons=mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[0]\n",
    "    + hl.str(mt.vep.transcript_consequences.protein_end[0])\n",
    "    + mt.vep.transcript_consequences.amino_acids[0].split(\"/\")[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5feb1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate variants of interest\n",
    "interesting_variants = hl.literal([\"missense_variant\", \"stop_gained\", \"frameshift_variant\", \"inframe_deletion\", \"start_lost\"])\n",
    "\n",
    "mt = mt.annotate_rows(is_interesting_var = interesting_variants.contains(mt.vep.most_severe_consequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47880eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:10:57 Hail: WARN: Found 1 duplicate column. Mangled columns follows:\n",
      "  'Fmut(EC50)' -> 'Fmut(EC50)_1'\n",
      "2023-01-31 11:10:57 Hail: INFO: Reading table to impute column types\n",
      "2023-01-31 11:10:58 Hail: WARN: Found 1 duplicate column. Mangled columns follows:\n",
      "  'Fmut(EC50)' -> 'Fmut(EC50)_1'\n",
      "2023-01-31 11:10:58 Hail: INFO: Finished type imputation\n",
      "  Loading field '\\ufeffAposA' as type str (imputed)\n",
      "  Loading field 'Location' as type str (imputed)\n",
      "  Loading field 'Bmax (Binding)' as type str (imputed)\n",
      "  Loading field 'sem (Bmax)' as type str (imputed)\n",
      "  Loading field 'logIC50 (Binding)' as type str (imputed)\n",
      "  Loading field 'sem (IC50)' as type str (imputed)\n",
      "  Loading field 'n (binding)' as type str (imputed)\n",
      "  Loading field 'Fmut (IC50)' as type str (imputed)\n",
      "  Loading field 'Emax (cAMP)' as type str (imputed)\n",
      "  Loading field 'sem (EC50)' as type str (imputed)\n",
      "  Loading field 'logEC50 (cAMP)' as type str (imputed)\n",
      "  Loading field 'sem (cAMP)' as type str (imputed)\n",
      "  Loading field 'Efficacy at 100pmol (cAMP)' as type str (imputed)\n",
      "  Loading field 'n (cAMP)' as type str (imputed)\n",
      "  Loading field 'Fmut(EC50)' as type str (imputed)\n",
      "  Loading field 'Emax (Arrestin)' as type str (imputed)\n",
      "  Loading field 'sem (Arrestin Emax))' as type str (imputed)\n",
      "  Loading field 'logEC50 (Arrestin)' as type str (imputed)\n",
      "  Loading field 'sem (Arrestin EC50)' as type str (imputed)\n",
      "  Loading field 'n (Arrestin)' as type str (imputed)\n",
      "  Loading field 'Fmut(EC50)_1' as type str (imputed)\n",
      "  Loading field '100pM efficacy' as type str (imputed)\n",
      "  Loading field 'Arrestin' as type str (imputed)\n",
      "  Loading field 'Binding' as type str (imputed)\n",
      "  Loading field 'GRCh_38_location' as type str (imputed)\n",
      "2023-01-31 11:10:58 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:59 Hail: INFO: merging 1 files totalling 7.8K...\n",
      "2023-01-31 11:10:59 Hail: INFO: while writing:\n",
      "    /tmp/GIPR/GIPR.invitro.tsv\n",
      "  merge time: 32.682ms\n",
      "2023-01-31 11:10:59 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:10:59 Hail: INFO: wrote table with 47 rows in 1 partition to /tmp/GIPR.invitro.ht\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'fs', '-get', '/tmp/GIPR/GIPR.invitro.tsv', '/opt/notebooks/gogoGPCR/data/GIPR/GIPR.invitro.tsv'], returncode=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in vitro data\n",
    "INVITRO_FILE=\"/opt/notebooks/gogoGPCR/data/GIPR/GIPR.invitro.csv\"\n",
    "run([\"hadoop\", \"fs\", \"-put\", str(INVITRO_FILE), \"/tmp\"])\n",
    "\n",
    "ht = hl.import_table(\"/tmp/GIPR.invitro.csv\", delimiter = \",\", impute = True)\n",
    "ht = ht.filter(ht.GRCh_38_location != \"\")\n",
    "ht = ht.annotate(variant = \"chr\" + ht.GRCh_38_location.replace(\"-\", \":\"))\n",
    "ht = ht.annotate(**hl.parse_variant(ht.variant))\n",
    "ht = ht.key_by(ht.locus, ht.alleles)\n",
    "ht.export(\"/tmp/GIPR/GIPR.invitro.tsv\")\n",
    "ht.write(\"/tmp/GIPR.invitro.ht\")\n",
    "\n",
    "run([\"hadoop\", \"fs\", \"-get\", \"/tmp/GIPR/GIPR.invitro.tsv\", \"/opt/notebooks/gogoGPCR/data/GIPR/GIPR.invitro.tsv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdff0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate with in vitro data\n",
    "mt = mt.annotate_rows(**ht[mt.locus, mt.alleles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41f2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORE_FILE=https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz\n",
    "# INDEX=IndexFile\n",
    "# curl -o $INDEX $SCORE_FILE.tbi\n",
    "# tabix $SCORE_FILE $INDEX --print-header 19:45668221-45683722 | tail -n +2 > ../../data/GIPR/GIPR.CADD.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74d50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:11:03 Hail: INFO: Reading table to impute column types\n",
      "2023-01-31 11:11:04 Hail: INFO: Finished type imputation\n",
      "  Loading field 'Chrom' as type int32 (imputed)\n",
      "  Loading field 'Pos' as type int32 (imputed)\n",
      "  Loading field 'Ref' as type str (imputed)\n",
      "  Loading field 'Alt' as type str (imputed)\n",
      "  Loading field 'RawScore' as type float64 (imputed)\n",
      "  Loading field 'PHRED' as type float64 (imputed)\n"
     ]
    }
   ],
   "source": [
    "# Import CADD scores\n",
    "run([\"hadoop\", \"fs\", \"-put\", \"../../data/GIPR/GIPR.CADD.tsv\", \"/tmp/GIPR.CADD.tsv\"])\n",
    "cadd = hl.import_table(\"/tmp/GIPR.CADD.tsv\", impute = True)\n",
    "cadd = cadd.annotate(variant_string = \"chr\" + hl.str(cadd.Chrom) + \":\" + hl.str(cadd.Pos) + \":\" + cadd.Ref + \":\" + cadd.Alt)\n",
    "cadd = cadd.annotate(**hl.parse_variant(cadd.variant_string))\n",
    "cadd = cadd.key_by(cadd.locus, cadd.alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1b3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate with CADD data\n",
    "mt = mt.annotate_rows(**cadd[mt.locus, mt.alleles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5f52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:11:05 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:11:06 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:12:25 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-01-31 11:12:26 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:12:26 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:12:27 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 11:16:56 Hail: INFO: wrote matrix table with 555 rows and 469835 columns in 3 partitions to /tmp/GIPR.ANNOTATED.cp.mt\n",
      "    Total size: 1.32 GiB\n",
      "    * Rows/entries: 1.32 GiB\n",
      "    * Columns: 3.07 MiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  483 rows (1.14 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint because Hail likes checkpointing\n",
    "stage = \"ANNOTATED\"\n",
    "checkpoint_file = f\"/tmp/GIPR.{stage}.cp.mt\"\n",
    "\n",
    "mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "# mt = hl.read_matrix_table(checkpoint_file)\n",
    "\n",
    "mt.filter_rows(~hl.is_missing(mt['Bmax (Binding)'])).count_rows() # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b13c9672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter oligo lots\n",
    "mt.count_rows()\n",
    "mt = mt.annotate_rows(DP10 = hl.agg.mean(mt.DP < 10)) # UKB recommend\n",
    "mt = mt.filter_rows(mt.DP10 < 0.90) # No variants\n",
    "mt.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b92336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries QC\n",
    "mt = mt.annotate_entries(AB=(mt.AD[1] / hl.sum(mt.AD)))\n",
    "\n",
    "mt = mt.filter_entries(\n",
    "    (mt.GQ >= 20) &\n",
    "    (\n",
    "        hl.is_indel(mt.alleles[0], mt.alleles[1]) & (mt.DP >= 10)) |\n",
    "        (hl.is_snp(mt.alleles[0], mt.alleles[1]) & (mt.DP >= 7)\n",
    "    ) &\n",
    "    (\n",
    "        (mt.GT.is_hom_ref() & (mt.AB <= 0.1)) |\n",
    "        (mt.GT.is_het() & (mt.AB >= 0.2) & (mt.AB <= 0.8)) |\n",
    "        (mt.GT.is_hom_var() & (mt.AB >= 0.9))\n",
    "    )\n",
    ") # Combine Backman and Pedersen\n",
    "\n",
    "mt = mt.compute_entry_filter_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89255a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for variant and sample QC\n",
    "mt = hl.variant_qc(mt)\n",
    "mt = hl.sample_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6a1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint QC\n",
    "stage = \"QC0\"\n",
    "checkpoint_file = f\"/tmp/GIPR.{stage}.cp.mt\"\n",
    "\n",
    "# mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "mt = hl.read_matrix_table(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e61aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variant QC\n",
    "mt = mt.filter_rows(~(mt.variant_qc.p_value_hwe < 10**-15)) # Backman, 2 variants, chr19:45674703 [\"C\",\"T\"] \"N170N\" and chr19:45677071 [\"G\",\"C\"]\"E252D\"\n",
    "mt = mt.filter_rows(mt.variant_qc.call_rate > 0.99) # Backman\n",
    "mt = mt.filter_rows(~hl.is_missing(mt.variant_qc.AF)) # 10 variants, no missense\n",
    "mt.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b83d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples remaining after removing withdrawn participants: 469817 \n"
     ]
    }
   ],
   "source": [
    "# Sample QC\n",
    "mt = mt.filter_cols(mt.sample_qc. call_rate > 0.9) # 1 sample\n",
    "mt = mt.filter_cols(~mt.s.startswith(\"W\"))\n",
    "\n",
    "print(f\"Samples remaining after removing withdrawn participants: {mt.count_cols()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed1b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:56:27 Hail: INFO: Reading table without type imputation\n",
      "  Loading field '' as type str (not specified)\n",
      "  Loading field 'PC_UKBB.eid' as type str (not specified)\n",
      "  Loading field 'group' as type str (not specified)\n"
     ]
    }
   ],
   "source": [
    "# Ancestry check\n",
    "run([\"hadoop\", \"fs\", \"-put\", \"ancestry.csv\", \"/tmp\"]) # from GIPR_ancestry.ipynb\n",
    "ht = hl.import_table(\"/tmp/ancestry.csv\", delimiter = \",\", quote='\"', missing=\"foo\").select(\"PC_UKBB.eid\", \"group\").key_by(\"PC_UKBB.eid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd84bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(**ht[mt.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7f8d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:56:27 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2023-01-31 11:56:59 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">group</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">num_carriers</div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">str</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">int64</td></tr>\n",
       "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Ashkenazi&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">22</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Caribbean&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">108</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;China&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">34</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;India&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">110</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Iran&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">18</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Italy&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">111</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;NA&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">206</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Nigeria&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">155</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Poland&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">68</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;United Kingdom&quot;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">10638</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">NA</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">13</td></tr>\n",
       "</tbody></table>"
      ],
      "text/plain": [
       "+------------------+--------------+\n",
       "| group            | num_carriers |\n",
       "+------------------+--------------+\n",
       "| str              |        int64 |\n",
       "+------------------+--------------+\n",
       "| \"Ashkenazi\"      |           22 |\n",
       "| \"Caribbean\"      |          108 |\n",
       "| \"China\"          |           34 |\n",
       "| \"India\"          |          110 |\n",
       "| \"Iran\"           |           18 |\n",
       "| \"Italy\"          |          111 |\n",
       "| \"NA\"             |          206 |\n",
       "| \"Nigeria\"        |          155 |\n",
       "| \"Poland\"         |           68 |\n",
       "| \"United Kingdom\" |        10638 |\n",
       "| NA               |           13 |\n",
       "+------------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:57:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-01-31 11:57:28 Hail: INFO: merging 11 files totalling 139...\n",
      "2023-01-31 11:57:29 Hail: INFO: while writing:\n",
      "    /tmp/n_ancestries.csv\n",
      "  merge time: 100.696ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'fs', '-get', '/tmp/n_ancestries.csv'], returncode=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt2 = mt.filter_rows(~hl.is_missing(mt['Bmax (Binding)']))\n",
    "mt2 = mt2.annotate_cols(carrier = hl.agg.any(mt2.GT.is_non_ref()))\n",
    "grp = mt2.select_cols(mt2.group, mt2.carrier).cols()\n",
    "grp = grp.group_by(grp.group).aggregate(num_carriers = hl.agg.sum(grp.carrier))\n",
    "grp.show(-1)\n",
    "grp.export('/tmp/n_ancestries.csv')\n",
    "run([\"hadoop\", \"fs\", \"-get\", \"/tmp/n_ancestries.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c38ad5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only United Kingdom\n",
    "# mt = mt.filter_cols(mt.group == \"United Kingdom\")\n",
    "mt.count_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b926fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint QC\n",
    "stage = \"QC1\"\n",
    "checkpoint_file = f\"/tmp/GIPR.{stage}.cp.mt\"\n",
    "\n",
    "# mt = mt.checkpoint(checkpoint_file, overwrite=True)\n",
    "# mt = hl.read_matrix_table(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae20a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:57:31 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'eid' as type str (not specified)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "465506"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove filtered samples\n",
    "s2r = hl.import_table(\"/tmp/samples_to_remove.tsv\").key_by('eid')\n",
    "mt = mt.anti_join_cols(s2r)\n",
    "mt.count_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514c9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variants no longer present\n",
    "mt = hl.variant_qc(mt)\n",
    "mt = mt.filter_rows(mt.variant_qc.n_non_ref != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b542e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceecf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANNOTATION\n",
    "mt = mt.annotate_rows(eff_mask = mt[\"100pM efficacy\"].replace(\"WT-like\", \"WT\"),\n",
    "                      arr_mask = mt.Arrestin.replace(\"WT-like\", \"WT\"))\n",
    "mt = mt.annotate_rows(label0 = mt.eff_mask + \"_\" + mt.arr_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3756550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozendict({'frameshift_variant': 16, 'inframe_deletion': 5, 'inframe_insertion': 2, 'missense_variant': 340, 'splice_region_variant': 5, 'start_lost': 2, 'stop_gained': 27, 'synonymous_variant': 138})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pLoF variant counts\n",
    "mt.aggregate_rows(hl.agg.counter(mt.vep.most_severe_consequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc710d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">locus</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">alleles</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">label</div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">locus&lt;GRCh38&gt;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">array&lt;str&gt;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">str</td></tr>\n",
       "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669521</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;A&quot;,&quot;ATGACTACCT&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">NA</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669521</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;A&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;pLoF&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669521</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;A&quot;,&quot;T&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;pLoF&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669554</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;missense_variant&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669557</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;T&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;WT_WT&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669559</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Synonymous&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669565</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;G&quot;,&quot;T&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;Synonymous&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669568</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;pLoF&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669569</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;G&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;missense_variant&quot;</td></tr>\n",
       "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">chr19:45669569</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;G&quot;,&quot;C&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">&quot;missense_variant&quot;</td></tr>\n",
       "</tbody></table><p style=\"background: #fdd; padding: 0.4em;\">showing top 10 rows</p>\n"
      ],
      "text/plain": [
       "+----------------+--------------------+--------------------+\n",
       "| locus          | alleles            | label              |\n",
       "+----------------+--------------------+--------------------+\n",
       "| locus<GRCh38>  | array<str>         | str                |\n",
       "+----------------+--------------------+--------------------+\n",
       "| chr19:45669521 | [\"A\",\"ATGACTACCT\"] | NA                 |\n",
       "| chr19:45669521 | [\"A\",\"G\"]          | \"pLoF\"             |\n",
       "| chr19:45669521 | [\"A\",\"T\"]          | \"pLoF\"             |\n",
       "| chr19:45669554 | [\"C\",\"G\"]          | \"missense_variant\" |\n",
       "| chr19:45669557 | [\"C\",\"T\"]          | \"WT_WT\"            |\n",
       "| chr19:45669559 | [\"C\",\"G\"]          | \"Synonymous\"       |\n",
       "| chr19:45669565 | [\"G\",\"T\"]          | \"Synonymous\"       |\n",
       "| chr19:45669568 | [\"C\",\"A\"]          | \"pLoF\"             |\n",
       "| chr19:45669569 | [\"G\",\"A\"]          | \"missense_variant\" |\n",
       "| chr19:45669569 | [\"G\",\"C\"]          | \"missense_variant\" |\n",
       "+----------------+--------------------+--------------------+\n",
       "showing top 10 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "frozendict({'GoF_WT': 1, 'LoF_LoF': 15, 'LoF_LoF ': 1, 'LoF_WT': 4, 'Synonymous': 163, 'WT_GoF': 1, 'WT_LoF': 4, 'WT_WT': 6, 'missense_variant': 230, 'pLoF': 103, None: 7})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label\n",
    "pLoF = hl.set([\"stop_gained\", \"frameshift_variant\", \"splice_region_variant\", \"start_lost\"])\n",
    "\n",
    "mt = mt.annotate_rows(label = hl.case()\n",
    "                         .when(~hl.is_missing(mt.label0), mt.label0)\n",
    "                         .when(pLoF.contains(mt.vep.most_severe_consequence) | (mt.PHRED > 30), 'pLoF')\n",
    "                         .when((mt.vep.most_severe_consequence == 'synonymous_variant') | (mt.PHRED < 10), 'Synonymous')\n",
    "                         .default(mt.vep.most_severe_consequence)\n",
    "#                          .or_missing()\n",
    "                )\n",
    "\n",
    "mt.label.show(10)\n",
    "mt.aggregate_rows(hl.agg.counter(mt.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24763a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 12:04:10 Hail: INFO: merging 2 files totalling 100.5K...\n",
      "2023-01-31 12:04:10 Hail: INFO: while writing:\n",
      "    /tmp/GIPR_new_variants_ALL.tsv\n",
      "  merge time: 33.103ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'fs', '-get', '/tmp/GIPR_new_variants_ALL.tsv'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary of variants\n",
    "intr = mt.rows()\n",
    "intr = intr.select(intr.variant_qc, intr.protCons, intr.label, intr.vep.most_severe_consequence, intr.PHRED)\n",
    "intr = intr.annotate(**intr.variant_qc)\n",
    "intr = intr.drop(\n",
    "    \"variant_qc\",\n",
    "    \"gq_stats\",\n",
    "    \"dp_stats\",\n",
    ")\n",
    "intr.export('/tmp/GIPR_new_variants_ALL.tsv')\n",
    "run([\"hadoop\", \"fs\", \"-get\", '/tmp/GIPR_new_variants_ALL.tsv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92bbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate regenioe files\n",
    "from matrixtables import write_bgen, add_varid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "335b526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BGEN_FILE = Path(\"/opt/notebooks/gogoGPCR/data/GIPR/GIPR\").resolve().__str__()\n",
    "ANNOTATIONS_FILE = Path(\"/opt/notebooks/gogoGPCR/data/GIPR/GIPR.annotations\").resolve().__str__()\n",
    "SETLIST_FILE = Path(\"/opt/notebooks/gogoGPCR/data/GIPR/GIPR.setlist\").resolve().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a34d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 12:07:36 Hail: INFO: while writing:\n",
      "    file:/opt/notebooks/gogoGPCR/data/GIPR/GIPR.bgen\n",
      "  merge time: 172.190ms\n",
      "2023-01-31 12:08:31 Hail: INFO: while writing:\n",
      "    file:/opt/notebooks/gogoGPCR/data/GIPR/GIPR.bgen\n",
      "  merge time: 161.490ms\n"
     ]
    }
   ],
   "source": [
    "# .bgen and .sample files\n",
    "write_bgen(mt, \"file:\" + BGEN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7b8ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 12:09:01 Hail: INFO: Coerced sorted dataset\n",
      "2023-01-31 12:09:29 Hail: INFO: merging 2 files totalling 19.0K...\n",
      "2023-01-31 12:09:29 Hail: INFO: while writing:\n",
      "    file:/opt/notebooks/gogoGPCR/data/GIPR/GIPR.annotations\n",
      "  merge time: 20.012ms\n"
     ]
    }
   ],
   "source": [
    "# .annotations file\n",
    "\n",
    "mt = add_varid(mt)\n",
    "\n",
    "annotations = (\n",
    "    mt.select_rows(\n",
    "        varid=mt.varid,\n",
    "        gene=mt.vep.transcript_consequences.gene_symbol[0],\n",
    "        annotation=mt.label,\n",
    "    )\n",
    "    .rows()\n",
    "    .key_by(\"varid\")\n",
    "    .drop(\"locus\")\n",
    "    .drop(\"alleles\")\n",
    ")\n",
    "\n",
    "annotations.export(\"file:\" + ANNOTATIONS_FILE, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b808492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .setlist file\n",
    "position = mt.aggregate_rows(hl.agg.min(mt.locus.position))\n",
    "names = mt.varid.collect()\n",
    "names_str = \",\".join(names)\n",
    "\n",
    "line = f\"{mt.vep.transcript_consequences.gene_symbol[0].collect()[0]}\\t{mt.locus.contig.collect()[0]}\\t{position}\\t{names_str}\"\n",
    "\n",
    "with open(SETLIST_FILE, \"w\") as f:\n",
    "    f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e4a7b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['dx', 'upload', '/opt/notebooks/gogoGPCR/data/GIPR/GIPR.bgen', '/opt/notebooks/gogoGPCR/data/GIPR/GIPR.sample', '/opt/notebooks/gogoGPCR/data/GIPR/GIPR.annotations', '/opt/notebooks/gogoGPCR/data/GIPR/GIPR.setlist', '--path', '/Data/burden/'], returncode=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dx upload\n",
    "bgen_file = BGEN_FILE + \".bgen\"\n",
    "sample_file = BGEN_FILE + \".sample\"\n",
    "\n",
    "run(\n",
    "    [\n",
    "        \"dx\",\n",
    "        \"upload\",\n",
    "        bgen_file,\n",
    "        sample_file,\n",
    "        ANNOTATIONS_FILE,\n",
    "        SETLIST_FILE,\n",
    "        \"--path\",\n",
    "        \"/Data/burden/\",\n",
    "    ],\n",
    "    check=True,\n",
    "    shell=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
