{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac80eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "import dxdata\n",
    "import dxpy\n",
    "import hail as hl\n",
    "import pyspark\n",
    "import tomli\n",
    "\n",
    "from utils import fields_for_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd067bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\n",
      "SparkUI available at http://ip-10-60-131-24.eu-west-2.compute.internal:8081\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.78-b17627756568\n",
      "LOGGING: writing to /opt/notebooks/gogoGPCR/notebooks/hail_logs/GIPR_1154.log\n"
     ]
    }
   ],
   "source": [
    "LOG_FILE = (\n",
    "    Path(\"../hail_logs\", f\"GIPR_{datetime.now().strftime('%H%M')}.log\")\n",
    "    .resolve()\n",
    "    .__str__()\n",
    ")\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "hl.init(sc=sc, default_reference=\"GRCh38\", log=LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e798056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispensed_database_name = dxpy.find_one_data_object(\n",
    "    classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True\n",
    ")[\"describe\"][\"name\"]\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n",
    ")[\"id\"]\n",
    "\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f322b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"22027\", \"22019\", \"22021\", \"21000\"]\n",
    "field_names = [\n",
    "    fields_for_id(i, participant) for i in fields\n",
    "]  # fields_for_id(\"22027\") + fields_for_id(\"22019\") + fields_for_id(\"22006\") + fields_for_id(\"22021\")\n",
    "field_names = [\"eid\"] + [field.name for fields in field_names for field in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31cfd30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples to be filtered: 4714\n"
     ]
    }
   ],
   "source": [
    "df = participant.retrieve_fields(\n",
    "    names=field_names, engine=dxdata.connect(), coding_values=\"replace\"\n",
    ")\n",
    "\n",
    "# Don't show eid\n",
    "# df.show(5, truncate=False)\n",
    "\n",
    "# Use hard filters\n",
    "\n",
    "df = df.filter(\n",
    "    (~df.p22027.isNull())\n",
    "    | (~df.p22019.isNull())\n",
    "    | (df.p22021 == \"Participant excluded from kinship inference process\")\n",
    "    | (df.p22021 == \"Ten or more third-degree relatives identified\")\n",
    "    | (df.p21000_i0 == \"White and Black Caribbean\")\n",
    "    | (df.p21000_i0 == \"White and Black African\")\n",
    "    | (df.p21000_i0 == \"White and Asian\")\n",
    "    | (df.p21000_i0 == \"Any other mixed background\")\n",
    ")\n",
    "filtered_samples_to_remove = hl.Table.from_spark(df.select(\"eid\")).key_by(\"eid\")\n",
    "print(f\"Samples to be filtered: {filtered_samples_to_remove.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "777ac512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 11:55:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-01-31 11:55:31 Hail: INFO: merging 9 files totalling 36.8K...\n",
      "2023-01-31 11:55:31 Hail: INFO: while writing:\n",
      "    /tmp/samples_to_remove.tsv\n",
      "  merge time: 95.368ms\n"
     ]
    }
   ],
   "source": [
    "filtered_samples_to_remove.export(\"/tmp/samples_to_remove.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c807a4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 10:14:01 Hail: INFO: Reading table to impute column types\n",
      "2023-01-30 10:14:10 Hail: INFO: Finished type imputation\n",
      "  Loading field 'ID1' as type str (user-supplied type)\n",
      "  Loading field 'ID2' as type str (user-supplied type)\n",
      "  Loading field 'HetHet' as type float64 (imputed)\n",
      "  Loading field 'IBS0' as type float64 (imputed)\n",
      "  Loading field 'Kinship' as type float64 (imputed)\n"
     ]
    }
   ],
   "source": [
    "UKB_REL_DAT_FILE = \"Bulk/Genotype Results/Genotype calls/ukb_rel.dat\"\n",
    "\n",
    "rel = hl.import_table(\n",
    "    \"file:\" + \"/mnt/project/\" + UKB_REL_DAT_FILE,\n",
    "    delimiter=\" \",\n",
    "    impute=True,\n",
    "    types={\"ID1\": \"str\", \"ID2\": \"str\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65b4210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 10:29:42 Hail: INFO: Reading table without type imputation\n",
      "  Loading field '' as type str (not specified)\n",
      "  Loading field 'PC_UKBB.eid' as type str (not specified)\n",
      "  Loading field 'group' as type str (not specified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446606\n"
     ]
    }
   ],
   "source": [
    "anc = hl.import_table('/tmp/ancestry.csv', delimiter = ',', quote = '\"')\n",
    "anc = anc.aggregate(hl.agg.filter(anc.group == \"United Kingdom\", hl.agg.collect_as_set(anc['PC_UKBB.eid'])))\n",
    "n_uk = len(anc)\n",
    "print(n_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38cfd33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of related: 22.922441704768858\n",
      "Number of samples with 2nd degree relatives 37936\n"
     ]
    }
   ],
   "source": [
    "n_rel = rel.filter(hl.set(anc).contains(rel.ID1) & hl.set(anc).contains(rel.ID2) & (rel.Kinship > 0.044)).count()\n",
    "n_2nd = rel.filter(hl.set(anc).contains(rel.ID1) & hl.set(anc).contains(rel.ID2) & (rel.Kinship > 0.0884)).count()\n",
    "print(f\"Proportion of related: {100 * n_rel / n_uk}\")\n",
    "print(f\"Number of samples with 2nd degree relatives {n_2nd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b593275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:05 Hail: INFO: Reading table to impute column types\n",
      "2022-08-20 22:50:09 Hail: INFO: Finished type imputation\n",
      "  Loading field 'ID1' as type str (user-supplied type)\n",
      "  Loading field 'ID2' as type str (user-supplied type)\n",
      "  Loading field 'HetHet' as type float64 (imputed)\n",
      "  Loading field 'IBS0' as type float64 (imputed)\n",
      "  Loading field 'Kinship' as type float64 (imputed)\n",
      "2022-08-20 22:50:12 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:13 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:15 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:16 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related samples not already in filter and low kinship coefficient: 33869\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# We opt for not filtering relatedness based on Regnie stated performance. See regenie supplementary tables 10-14\n",
    "\n",
    "# rel = (\n",
    "#     rel.key_by(\"ID2\")\n",
    "#     .anti_join(filtered_samples_to_remove)\n",
    "#     .key_by(\"ID1\")\n",
    "#     .anti_join(filtered_samples_to_remove)\n",
    "# )\n",
    "\n",
    "# rel = rel.filter(rel.Kinship > 0.125, keep=True)\n",
    "\n",
    "# print(\n",
    "#     f\"Related samples not already in filter and low kinship coefficient: {rel.count()}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c45a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:18 Hail: INFO: Reading table to impute column types\n",
      "2022-08-20 22:50:19 Hail: INFO: Finished type imputation\n",
      "  Loading field 's' as type str (user-supplied type)\n",
      "  Loading field 'is_interesting_sample' as type bool (imputed)\n"
     ]
    }
   ],
   "source": [
    "# Carriers of variants of interest\n",
    "\n",
    "# samples = hl.import_table(\"/opt/notebooks/gogoGPCR_private/data/GIPR/interesting_samples.tsv\", impute = True, types={\"s\": \"str\"}).key_by(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b34296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structures for interesting variants\n",
    "\n",
    "# rel_interesting = rel.key_by(\n",
    "#     i=hl.struct(id=rel.ID1,\n",
    "#                 is_int=samples[rel.ID1].is_interesting_sample,\n",
    "#                 is_def=hl.is_defined(samples[rel.ID1].is_interesting_sample)),\n",
    "#     j=hl.struct(id=rel.ID2,\n",
    "#                 is_int=samples[rel.ID2].is_interesting_sample,\n",
    "#                 is_def=hl.is_defined(samples[rel.ID2].is_interesting_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tie breaker preferring carriers of interesting variants\n",
    "\n",
    "# def tie_breaker(l, r):\n",
    "#     is_def_and_int = (hl.case()\n",
    "#               .when(l.is_def & ~r.is_def, -1)\n",
    "#               .when(~l.is_def & r.is_def, 1)\n",
    "#               .when(~l.is_def & ~r.is_def, 0)\n",
    "#               .when(l.is_def & r.is_def,\n",
    "#                    (hl.case()\n",
    "#                     .when(l.is_int & ~r.is_int, -1)\n",
    "#                     .when(~l.is_int & r.is_int, 1)\n",
    "#                     .when(~l.is_int & ~r.is_int, 0)\n",
    "#                     .when(l.is_int & r.is_int, 0).default(-9)\n",
    "#                )).default(-9)\n",
    "#              )\n",
    "#     return is_def_and_int\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2f038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:20 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:21 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:22 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:23 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:23 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:24 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:32 Hail: INFO: Coerced sorted dataset\n",
      "2022-08-20 22:50:32 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:36 Hail: INFO: wrote table with 33869 rows in 1 partition to /tmp/c8GwwJq7o8Rb5Spb7PfwsW\n",
      "2022-08-20 22:50:38 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples to remove to create independent set: 29877\n"
     ]
    }
   ],
   "source": [
    "# Create an independent set by removing related nodes in the graph\n",
    "\n",
    "# related_samples_to_remove = (\n",
    "#     hl.maximal_independent_set(\n",
    "#         i=rel_interesting.i,\n",
    "#         j=rel_interesting.j,\n",
    "#         keep=False,\n",
    "#         tie_breaker=tie_breaker\n",
    "#     )\n",
    "\n",
    "# print(\n",
    "#     f\"Samples to remove to create independent set: {related_samples_to_remove.count()}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b1c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# related_samples_to_remove = related_samples_to_remove.key_by(eid = related_samples_to_remove.node.id).drop(\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5b678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166259"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before removal\n",
    "\n",
    "# samples.aggregate(hl.agg.sum(samples.is_interesting_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c869b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = samples.filter(hl.is_defined(related_samples_to_remove[samples.s]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d73e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:40 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:40 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:40 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159590"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With tie break\n",
    "\n",
    "# result.aggregate(hl.agg.sum(result.is_interesting_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b043d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:43 Hail: INFO: Table.join: renamed the following fields on the right to avoid name conflicts:\n",
      "    'eid' -> 'eid_1'\n",
      "2022-08-20 22:50:43 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:43 Hail: INFO: Coerced sorted dataset\n",
      "2022-08-20 22:50:44 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of samples to remove: 31692\n"
     ]
    }
   ],
   "source": [
    "# We opt for not removing related individuals\n",
    "\n",
    "# final = related_samples_to_remove.join(filtered_samples_to_remove, how=\"outer\")\n",
    "# print(f\"Final number of samples to remove: {final.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83fc57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = samples.filter(hl.is_defined(final[samples.s]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14eeb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:46 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:46 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:46 Hail: INFO: Coerced sorted dataset\n",
      "2022-08-20 22:50:47 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158989"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.aggregate(hl.agg.sum(result.is_interesting_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ba3127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:50:54 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:54 Hail: INFO: Coerced sorted dataset\n",
      "2022-08-20 22:50:55 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2022-08-20 22:50:57 Hail: INFO: merging 49 files totalling 247.6K...\n",
      "2022-08-20 22:50:57 Hail: INFO: while writing:\n",
      "    /tmp/samples_to_remove2.tsv\n",
      "  merge time: 301.608ms\n"
     ]
    }
   ],
   "source": [
    "# final.export(\"/tmp/samples_to_remove2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42fc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
